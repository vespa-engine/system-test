# Copyright Vespa.ai. All rights reserved.

require 'performance/nearest_neighbor/common_mips_base'

class NearestNeighborMipsMind < CommonMipsBase

  def setup
    super
    set_owner("boeker")
  end

  def test_mips_with_mind_dataset
    set_description("Test performance and recall for MIPS using the MIND dataset")

    # This test uses the Microsoft News Dataset (MIND) (https://msnews.github.io/).
    # MIND contains about 160k English news articles and more than 15 million impression logs generated by 1 million users.
    #
    # In the following Vespa tutorial (https://docs.vespa.ai/en/tutorials/news-4-embeddings.html)
    # we explain how to use this dataset to train a model with news embeddings and user embeddings for collaborative filtering.
    #
    # To recreate the small dataset:
    # 1) Checkout sample app:
    #   cd $HOME/git
    #   git clone git@github.com:vespa-engine/sample-apps.git
    #   cd sample-apps/news
    #
    # 2) Download MIND small:
    #   ./bin/download-mind.sh small
    #
    # 3) Train the dataset:
    #   python3 -m pip install -r requirements.txt
    #   python3 src/python/create_bert_embeddings.py mind
    #   sed -i 's/embedding_size = 50/embedding_size = 128/g' src/python/train_cold_start.py
    #   python3 src/python/train_cold_start.py mind 10
    #
    # Training the small model took around 4 hours on perf14.
    # The result are two files in mind/
    #   news_embeddings.tsv - 65238 rows
    #   user_embeddings.tsv - 94057 rows
    #
    # To recreate the large dataset, replace 'small' with 'large' in the scripts above.
    # Training the large model (with 4 epochs instead of 10) took around 112 hours on perf14.
    #
    # Convert to Vespa documents and queries using scripts part of this test:
    #   python3 mips/mind/create_news_docs.py news_embeddings.tsv > news_docs.small.json
    #   python3 mips/mind/create_user_queries.py user_embeddings.tsv 10000 > user_queries.small.txt
    #   python3 mips/mind/create_user_queries.py user_embeddings.tsv 1000 vectors > user_vectors.small.txt
    #
    #   python3 mips/mind/create_news_docs.py news_embeddings.large.tsv > news_docs.large.json
    #   python3 mips/mind/create_user_queries.py user_embeddings.large.tsv 10000 > user_queries.large.10k.txt
    #   python3 mips/mind/create_user_queries.py user_embeddings.large.tsv 1000 vectors > user_vectors.large.1k.txt
    #
    # How to upload data files to S3 is described here:
    # https://docs-internal.vespa.ai/documentation/devguide/model-hub.html

    @news_docs = @data_path + "news_docs.large.json"
    @queries = @data_path + "user_queries.large.10k.txt"
    @query_vectors = @data_path + "user_vectors.large.1k.txt"

  # @news_docs = @data_path + "news_docs.small.json"
  # @queries = @data_path + "user_queries.small.txt"
  # @query_vectors = @data_path + "user_vectors.small.txt"

    run_mips_test(selfdir + "mips/mind/news.sd", @news_docs, "news", "user")
  end


end
