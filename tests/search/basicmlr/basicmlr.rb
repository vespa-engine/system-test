# Copyright Vespa.ai. All rights reserved.
require 'json'
require 'indexed_streaming_search_test'
require 'environment'
require 'document_set'

class BasicMLR < IndexedStreamingSearchTest

  def setup
    set_owner("lesters")
    @mytmpdir = dirs.tmpdir
    puts("Using temporary directory '#{@mytmpdir}'..")
    @feed_file = @mytmpdir + "vespafeed.json"
  end

  def test_basicMLR

    # Deploy classicrank application.
    @sd_dir = @mytmpdir + "schemas"
    FileUtils.mkdir_p(@sd_dir)
    deployApp("nativeRank")
    start

    # Generate a set of documents to use for this test.
    puts("Building Vespa feed..")

    feed = ""
    documents = DocumentSet.new
    0.upto(9) do |a|
      0.upto(9) do |b|
        0.upto(9) do |c|
          documents.add(createDocument(a / 10.0, b / 10.0, c / 10.0))
        end
      end
    end
    documents.write_json(@feed_file)

    feedDocuments
    assertDocuments

    gbdt_output = File.open("#{selfdir}/output.xml").read.gsub("$PATH", @mytmpdir)
    vespa.adminserver.writefile(gbdt_output, "#{@mytmpdir}/output.xml")
    vespa.adminserver.execute("vespa-gbdt-converter #{@mytmpdir}/output.xml " +
                              "> #{@mytmpdir}/firstphase.expression.raw")
    vespa.adminserver.execute("tr [:upper:] [:lower:] " +
                              "< #{@mytmpdir}/firstphase.expression.raw " +
                              "> #{@mytmpdir}/firstphase.expression");

    @sd_dir = @mytmpdir + "schemas2"
    FileUtils.mkdir_p(@sd_dir)
    vespa.nodeproxies.first[1].copy_remote_file_into_local_directory("#{@mytmpdir}/firstphase.expression", @sd_dir)

    # Redeploy the application using the new ranking.
    puts("Deploying the new configuration..")
    deploy_output = deployApp("file:firstphase.expression")

    # wait until container and proton has gotten new config
    wait_for_application(vespa.container.values.first, deploy_output)
    vespa.storage['search'].wait_until_content_nodes_have_config_generation(get_generation(deploy_output).to_i)

    assertDocuments

    # The top hits should now have relevancy scores around 4
    result = search('query=sddocname:mlr&hits=10&type=all')
    0.upto(9) do |i|
      assert_relevancy(result, 4, i, 3.9)
    end

  end

  def deployApp(rank)
    file = File.open("#{@sd_dir}/mlr.sd", "w")
    file.print(File.open("#{selfdir}/template.sd").read.gsub("$RANK", rank))
    file.close
    app = SearchApp.new.sd("#{@sd_dir}/mlr.sd")
    app.rank_expression_file("#{@sd_dir}/#{rank.split('file:')[ 1]}") if rank.start_with?("file:")
    deploy_app(app)
  end

  def feedDocuments
    # Feed the autogenerated documents to the new setup.
    puts("Feeding to Vespa..")
    feed_and_wait_for_docs("mlr", 1000, :file => @feed_file)
  end

  def assertDocuments
    # Ensure that all the documents have been indexed.
    puts("Ensuring that the documents are available..")
    assert_hitcount('query=sddocname:mlr&type=all', 1000)
    assert_hitcount('query=a:[0.09%3B0.11]&type=all', 100)
    assert_hitcount('query=b:[0.09%3B0.11]&type=all', 100)
    assert_hitcount('query=c:[0.09%3B0.11]&type=all', 100)
    assert_hitcount('query=a:[0.09%3B0.11]+b:[0.09%3B0.11]&type=all', 10)
    assert_hitcount('query=b:[0.09%3B0.11]+c:[0.09%3B0.11]&type=all', 10)
    assert_hitcount('query=c:[0.09%3B0.11]+a:[0.09%3B0.11]&type=all', 10)
    assert_hitcount('query=a:[0.09%3B0.11]+b:[0.09%3B0.11]+c:[0.09%3B0.11]&type=all', 1)
  end

  def createDocument(a, b, c)
    doc = Document.new("id:scheme:mlr::" + a.to_s + "_" + b.to_s + "_" + c.to_s).
      add_field("a", a).
      add_field("b", b).
      add_field("c", c).
      add_field("label", (5 * (a + b + c) / 3).floor)
    return doc
  end

  def teardown
    stop
  end

end
